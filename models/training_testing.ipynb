{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys: ['curves']\n",
      "Total curves: 392\n",
      "\n",
      "=== Curve 1 / 2 ===\n",
      "Curve keys: ['id', 'curve_id', 'curve_label', 'alloy_composition', 'curve_raw_data', 'Kocks–Mecking_hardening_parameters']\n",
      "Alloy composition: {'Co': 20.0, 'Cr': 20.0, 'Fe': 20.0, 'Mn': 20.0, 'Ni': 20.0}\n",
      "Raw points count: 50\n",
      "First 5 raw points:\n",
      "{'x': 0.011, 'y': 592.329}\n",
      "{'x': 0.019, 'y': 614.075}\n",
      "{'x': 0.031, 'y': 635.802}\n",
      "{'x': 0.041, 'y': 661.89}\n",
      "{'x': 0.054, 'y': 683.61}\n",
      "\n",
      "=== Curve 2 / 2 ===\n",
      "Curve keys: ['id', 'curve_id', 'curve_label', 'alloy_composition', 'curve_raw_data', 'Kocks–Mecking_hardening_parameters']\n",
      "Alloy composition: {'Co': 20.0, 'Cr': 20.0, 'Fe': 20.0, 'Mn': 20.0, 'Ni': 20.0}\n",
      "Raw points count: 35\n",
      "First 5 raw points:\n",
      "{'x': 0.009, 'y': 359.309}\n",
      "{'x': 0.019, 'y': 383.219}\n",
      "{'x': 0.031, 'y': 400.59}\n",
      "{'x': 0.04, 'y': 415.796}\n",
      "{'x': 0.051, 'y': 430.996}\n"
     ]
    }
   ],
   "source": [
    "# Load JSON\n",
    "with open('combined_papers.json') as f:\n",
    "    data = json.load(f)\n",
    "num_preview = 2  # change this to print more or fewer curves\n",
    "\n",
    "if DEBUG:\n",
    "    print(\"Top-level keys:\", list(data.keys()))\n",
    "    print(\"Total curves:\", len(data.get('curves', [])))\n",
    "\n",
    "    curves = data.get('curves', [])[:num_preview]\n",
    "\n",
    "    for i, curve in enumerate(curves, start=1):\n",
    "        print(f\"\\n=== Curve {i} / {num_preview} ===\")\n",
    "\n",
    "        # Show available keys at this curve level\n",
    "        print(\"Curve keys:\", list(curve.keys()))\n",
    "\n",
    "        # Try to display alloy composition if present\n",
    "        if 'alloy_composition' in curve:\n",
    "            print(\"Alloy composition:\", curve['alloy_composition'])\n",
    "\n",
    "        # Safely get raw curve data\n",
    "        raw = curve.get('curve_raw_data', {}).get('data', [])\n",
    "        print(\"Raw points count:\", len(raw))\n",
    "\n",
    "        # Print first 5 (x, y) points\n",
    "        print(\"First 5 raw points:\")\n",
    "        for p in raw[:5]:\n",
    "            print(p)\n",
    "\n",
    "\n",
    "# Convert to DataFrame (if you want tabular format)\n",
    "#df = pd.json_normalize(data['curves'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Define the feature extraction function FIRST\n",
    "def extract_features_from_curve(curve_data):\n",
    "    \"\"\"\n",
    "    Extract comprehensive features from a stress-strain curve.\n",
    "    \"\"\"\n",
    "    # Check if the curve data exists and has enough points to compute features.\n",
    "    # If the curve is missing (None or empty) or contains fewer than 6 data points,\n",
    "    # return None to skip processing — this prevents errors when calculating\n",
    "    # slopes, toughness, or other curve parameters that require multiple points.    \n",
    "    if not curve_data or len(curve_data) < 6:\n",
    "        return None\n",
    "    \n",
    "    #Convert the list of dictionaries into NumPy arrays for efficient numerical computation.\n",
    "    # Each element in 'curve_data' contains {'x': strain, 'y': stress}.\n",
    "    # This comprehension extracts all 'x' values (strain) and all 'y' values (stress) into separate arrays\n",
    "    strains_unsorted = np.array([point['x'] for point in curve_data])\n",
    "    stresses_unsorted = np.array([point['y'] for point in curve_data])\n",
    "\n",
    "    \n",
    "\n",
    "      \n",
    "    # Sort by strain\n",
    "    sort_idx = np.argsort(strains_unsorted)\n",
    "    strains = strains_unsorted[sort_idx]\n",
    "    stresses = stresses_unsorted[sort_idx]\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # === Basic Mechanical Properties ===\n",
    "    features['ultimate_tensile_strength'] = np.max(stresses)\n",
    "    features['max_strain'] = np.max(strains)\n",
    "    features['uts_strain'] = strains[np.argmax(stresses)]\n",
    "    \n",
    "    # Yield strength approximation\n",
    "    if strains[0] <= 0.002 <= strains[-1]:\n",
    "        f_interp = interp1d(strains, stresses, kind='linear', fill_value='extrapolate')\n",
    "        features['yield_strength_002'] = float(f_interp(0.002))\n",
    "    else:\n",
    "        features['yield_strength_002'] = stresses[0]\n",
    "    \n",
    "    # === Stress at specific strain points ===\n",
    "    strain_points = [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "    for sp in strain_points:\n",
    "        if strains[0] <= sp <= strains[-1]:\n",
    "            f_interp = interp1d(strains, stresses, kind='linear', fill_value='extrapolate')\n",
    "            features[f'stress_at_{sp}'] = float(f_interp(sp))\n",
    "        else:\n",
    "            features[f'stress_at_{sp}'] = np.nan\n",
    "    \n",
    "    # === Work Hardening Analysis ===\n",
    "    if len(strains) > 5:\n",
    "        window = min(5, len(stresses) if len(stresses) % 2 == 1 else len(stresses) - 1)\n",
    "        if window >= 3:\n",
    "            stresses_smooth = savgol_filter(stresses, window, 2)\n",
    "        else:\n",
    "            stresses_smooth = stresses\n",
    "        \n",
    "        d_stress = np.diff(stresses_smooth)\n",
    "        d_strain = np.diff(strains)\n",
    "        hardening_rate = d_stress / (d_strain + 1e-10)\n",
    "        \n",
    "        features['avg_hardening_rate'] = np.mean(hardening_rate)\n",
    "        features['max_hardening_rate'] = np.max(hardening_rate)\n",
    "        features['min_hardening_rate'] = np.min(hardening_rate)\n",
    "        features['std_hardening_rate'] = np.std(hardening_rate)\n",
    "        \n",
    "        n_points = len(hardening_rate)\n",
    "        features['hardening_rate_early'] = np.mean(hardening_rate[:n_points//3])\n",
    "        features['hardening_rate_mid'] = np.mean(hardening_rate[n_points//3:2*n_points//3])\n",
    "        features['hardening_rate_late'] = np.mean(hardening_rate[2*n_points//3:])\n",
    "    \n",
    "    # === Energy Metrics ===\n",
    "    features['toughness'] = np.trapz(stresses, strains)\n",
    "    elastic_idx = int(len(strains) * 0.2)\n",
    "    features['resilience'] = np.trapz(stresses[:elastic_idx], strains[:elastic_idx])\n",
    "    \n",
    "    # === Statistical Features ===\n",
    "    features['stress_mean'] = np.mean(stresses)\n",
    "    features['stress_std'] = np.std(stresses)\n",
    "    features['stress_median'] = np.median(stresses)\n",
    "    features['stress_25_percentile'] = np.percentile(stresses, 25)\n",
    "    features['stress_75_percentile'] = np.percentile(stresses, 75)\n",
    "    features['stress_range'] = np.max(stresses) - np.min(stresses)\n",
    "    \n",
    "    # === Curve Shape Features ===\n",
    "    features['num_data_points'] = len(strains)\n",
    "    features['strain_range'] = np.max(strains) - np.min(strains)\n",
    "    \n",
    "    n = len(strains)\n",
    "    early_slope = (stresses[n//4] - stresses[0]) / (strains[n//4] - strains[0] + 1e-10)\n",
    "    mid_slope = (stresses[n//2] - stresses[n//4]) / (strains[n//2] - strains[n//4] + 1e-10)\n",
    "    late_slope = (stresses[-1] - stresses[n//2]) / (strains[-1] - strains[n//2] + 1e-10)\n",
    "    \n",
    "    features['early_slope'] = early_slope\n",
    "    features['mid_slope'] = mid_slope\n",
    "    features['late_slope'] = late_slope\n",
    "    \n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/0xhnpbcd2fsby1z0rgb21v_40000gn/T/ipykernel_20431/3631738977.py:73: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  features['toughness'] = np.trapz(stresses, strains)\n",
      "/var/folders/xy/0xhnpbcd2fsby1z0rgb21v_40000gn/T/ipykernel_20431/3631738977.py:75: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  features['resilience'] = np.trapz(stresses[:elastic_idx], strains[:elastic_idx])\n",
      "/opt/homebrew/lib/python3.11/site-packages/scipy/interpolate/_interpolate.py:479: RuntimeWarning: divide by zero encountered in divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n",
      "/opt/homebrew/lib/python3.11/site-packages/scipy/interpolate/_interpolate.py:482: RuntimeWarning: invalid value encountered in multiply\n",
      "  y_new = slope*(x_new - x_lo)[:, None] + y_lo\n"
     ]
    }
   ],
   "source": [
    "# Extract features into DataFrame for ML (tabular)\n",
    "feature_list = []\n",
    "composition_list = []\n",
    "\n",
    "for curve in data['curves']:\n",
    "    # Extract features (this makes it tabular)\n",
    "    features = extract_features_from_curve(curve['curve_raw_data']['data'])\n",
    "    feature_list.append(features)\n",
    "    composition_list.append(curve['alloy_composition'])\n",
    "\n",
    "# NOW you have tabular data for ML\n",
    "X = pd.DataFrame(feature_list)  # Features (tabular)\n",
    "y = pd.DataFrame(composition_list)  # Target (tabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strains_unsorted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33munsorted strain\u001b[39m\u001b[33m\"\u001b[39m,\u001b[43mstrains_unsorted\u001b[49m[:\u001b[32m3\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'strains_unsorted' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"unsorted strain\",strains_unsorted[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Load JSON\n",
    "with open('combined_papers.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Define the feature extraction function\n",
    "def extract_features_from_curve(curve_data):\n",
    "    \"\"\"Extract comprehensive features from a stress-strain curve.\"\"\"\n",
    "    if not curve_data or len(curve_data) < 3:\n",
    "        return None\n",
    "    \n",
    "    # Convert to arrays\n",
    "    strains = np.array([point['x'] for point in curve_data])\n",
    "    stresses = np.array([point['y'] for point in curve_data])\n",
    "    \n",
    "    # Sort by strain\n",
    "    sort_idx = np.argsort(strains)\n",
    "    strains = strains[sort_idx]\n",
    "    stresses = stresses[sort_idx]\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # === Basic Mechanical Properties ===\n",
    "    features['ultimate_tensile_strength'] = np.max(stresses)\n",
    "    features['max_strain'] = np.max(strains)\n",
    "    features['uts_strain'] = strains[np.argmax(stresses)]\n",
    "    \n",
    "    # Yield strength approximation\n",
    "    if strains[0] <= 0.002 <= strains[-1]:\n",
    "        f_interp = interp1d(strains, stresses, kind='linear', fill_value='extrapolate')\n",
    "        features['yield_strength_002'] = float(f_interp(0.002))\n",
    "    else:\n",
    "        features['yield_strength_002'] = stresses[0]\n",
    "    \n",
    "    # === Stress at specific strain points ===\n",
    "    strain_points = [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "    for sp in strain_points:\n",
    "        if strains[0] <= sp <= strains[-1]:\n",
    "            f_interp = interp1d(strains, stresses, kind='linear', fill_value='extrapolate')\n",
    "            features[f'stress_at_{sp}'] = float(f_interp(sp))\n",
    "        else:\n",
    "            features[f'stress_at_{sp}'] = np.nan\n",
    "    \n",
    "    # === Work Hardening Analysis ===\n",
    "    if len(strains) > 5:\n",
    "        window = min(5, len(stresses) if len(stresses) % 2 == 1 else len(stresses) - 1)\n",
    "        if window >= 3:\n",
    "            stresses_smooth = savgol_filter(stresses, window, 2)\n",
    "        else:\n",
    "            stresses_smooth = stresses\n",
    "        \n",
    "        d_stress = np.diff(stresses_smooth)\n",
    "        d_strain = np.diff(strains)\n",
    "        hardening_rate = d_stress / (d_strain + 1e-10)\n",
    "        \n",
    "        features['avg_hardening_rate'] = np.mean(hardening_rate)\n",
    "        features['max_hardening_rate'] = np.max(hardening_rate)\n",
    "        features['min_hardening_rate'] = np.min(hardening_rate)\n",
    "        features['std_hardening_rate'] = np.std(hardening_rate)\n",
    "        \n",
    "        n_points = len(hardening_rate)\n",
    "        features['hardening_rate_early'] = np.mean(hardening_rate[:n_points//3])\n",
    "        features['hardening_rate_mid'] = np.mean(hardening_rate[n_points//3:2*n_points//3])\n",
    "        features['hardening_rate_late'] = np.mean(hardening_rate[2*n_points//3:])\n",
    "    \n",
    "    # === Energy Metrics ===\n",
    "    features['toughness'] = np.trapz(stresses, strains)\n",
    "    elastic_idx = int(len(strains) * 0.2)\n",
    "    features['resilience'] = np.trapz(stresses[:elastic_idx], strains[:elastic_idx])\n",
    "    \n",
    "    # === Statistical Features ===\n",
    "    features['stress_mean'] = np.mean(stresses)\n",
    "    features['stress_std'] = np.std(stresses)\n",
    "    features['stress_median'] = np.median(stresses)\n",
    "    features['stress_25_percentile'] = np.percentile(stresses, 25)\n",
    "    features['stress_75_percentile'] = np.percentile(stresses, 75)\n",
    "    features['stress_range'] = np.max(stresses) - np.min(stresses)\n",
    "    \n",
    "    # === Curve Shape Features ===\n",
    "    features['num_data_points'] = len(strains)\n",
    "    features['strain_range'] = np.max(strains) - np.min(strains)\n",
    "    \n",
    "    n = len(strains)\n",
    "    early_slope = (stresses[n//4] - stresses[0]) / (strains[n//4] - strains[0] + 1e-10)\n",
    "    mid_slope = (stresses[n//2] - stresses[n//4]) / (strains[n//2] - strains[n//4] + 1e-10)\n",
    "    late_slope = (stresses[-1] - stresses[n//2]) / (strains[-1] - strains[n//2] + 1e-10)\n",
    "    \n",
    "    features['early_slope'] = early_slope\n",
    "    features['mid_slope'] = mid_slope\n",
    "    features['late_slope'] = late_slope\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features for all curves\n",
    "feature_list = []\n",
    "composition_list = []\n",
    "\n",
    "for curve in data['curves']:\n",
    "    features = extract_features_from_curve(curve['curve_raw_data']['data'])\n",
    "    if features is not None:\n",
    "        feature_list.append(features)\n",
    "        composition_list.append(curve['alloy_composition'])\n",
    "\n",
    "# Create DataFrames\n",
    "X = pd.DataFrame(feature_list)\n",
    "y = pd.DataFrame(composition_list)\n",
    "\n",
    "print(f\"✓ Feature extraction complete!\")\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target matrix shape: {y.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
